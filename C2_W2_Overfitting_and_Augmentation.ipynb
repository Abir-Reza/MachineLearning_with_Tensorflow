{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C2_W2_Overfitting_and_Augmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN7ckrzPeua2YHG6bDyHVjN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abir-Reza/MachineLearning_with_Tensorflow/blob/master/C2_W2_Overfitting_and_Augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llmLWD35TpHI"
      },
      "source": [
        "#**Overfiting** and effect of **Image augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7akO5kVTHnC"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip\n",
        "  \n",
        "import os\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvNGjzDkUHcN"
      },
      "source": [
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# # Directory with our training cat pictures\n",
        "# train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "\n",
        "# # Directory with our training dog pictures\n",
        "# train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# # Directory with our validation cat pictures\n",
        "# validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "\n",
        "# # Directory with our validation dog pictures\n",
        "# validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(lr=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GzhxN2UZiqF"
      },
      "source": [
        "#Image without Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb6ylEEgZnaZ",
        "outputId": "88b67d2f-0dd6-4c5c-d9f7-0561551298d3"
      },
      "source": [
        "#Rescale all images\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        " # flow from directory train_datagen\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "     train_dir, # this is source directory for training images\n",
        "     target_size =(150,150),\n",
        "     batch_size = 20,\n",
        "     #since we are using binary croos entropy loss function, we need binary class labels\n",
        "     class_mode ='binary')\n",
        "\n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1TjuPoXeSCj"
      },
      "source": [
        "#Model fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9Hx_tS6eU0Q"
      },
      "source": [
        "history = model.fit(\n",
        "    train_generator,steps_per_epoch =100, # 2000images = batch_size * steps_per_epoch\n",
        "    epochs =100,\n",
        "    verbose =2,\n",
        "    validation_data =validation_generator,\n",
        "    validation_steps =50,\n",
        "    \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfPkE0t55_-B"
      },
      "source": [
        "#Visualization of train and test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnHMPDCT58CS"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVjWGQfB667v"
      },
      "source": [
        "These are just a few of the options available (for more, see the Keras documentation. Let's quickly go over what we just wrote:\n",
        "\n",
        "* rotation_range is a value in degrees (0â€“180), a range within which to randomly rotate pictures.\n",
        "* width_shift and height_shift are ranges (as a fraction of total width or height) within which to randomly translate pictures vertically or horizontally.\n",
        "* shear_range is for randomly applying shearing transformations.\n",
        "* zoom_range is for randomly zooming inside pictures.\n",
        "* horizontal_flip is for randomly flipping half of the images horizontally. This is relevant when there are no assumptions of horizontal assymmetry (e.g. real-world pictures).\n",
        "* fill_mode is the strategy used for filling in newly created pixels, which can appear after a rotation or a width/height shift."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GilCpTFY7bp5"
      },
      "source": [
        "# Updated to do image augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaFvNNS-7qYJ"
      },
      "source": [
        "Result: Overfitting reduces after data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBZwlL2w68CP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}